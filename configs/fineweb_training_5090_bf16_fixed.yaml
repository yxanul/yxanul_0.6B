# BF16 config with data loading fixes for RTX 5090
# Fixes the 30-second data loading pauses

model_name: "yxanul-270m"
model_type: "decoder-only"

data:
  max_sequence_length: 2048
  dataset_name: "Yxanul/experimental-pretrain-1b"
  dataset_path: "experimental-pretrain-1b"
  dataset_file: "dataset_1b.parquet"
  streaming: false
  use_mmap: true
  num_proc: 4
  pack_sequences: false  # Disable for now to simplify debugging

training:
  num_epochs: 3
  warmup_steps: 2000
  max_steps: -1
  learning_rate: 1.6e-4
  min_learning_rate: 1.6e-5
  weight_decay: 0.1
  use_curriculum: false  # DISABLE curriculum to avoid dataloader recreation
  
  # Fixed batch size - no curriculum changes
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 16  # Effective batch = 64
  gradient_checkpointing: true
  mixed_precision: "bf16"
  tf32: true
  
  # DISABLE FP8 for stability
  use_fp8: false

validation:
  validation_split: 0.05
  per_device_eval_batch_size: 1
  eval_steps: 2000
  eval_strategy: "steps"
  metric_for_best_model: "perplexity"
  greater_is_better: false
  load_best_model_at_end: true

logging:
  logging_steps: 100
  save_steps: 5000
  save_total_limit: 3
  report_to: ["wandb"]
  run_name: "yxanul-270m-bf16-fixed"
  
checkpointing:
  save_strategy: "steps"
  save_steps: 5000
  save_total_limit: 3
  save_best_model: true
  resume_from_checkpoint: null

optimization:
  optim: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.98
  adam_epsilon: 1e-8
  max_grad_norm: 1.0
  lr_scheduler_type: "cosine"
  
  # Torch compile (can enable for BF16)
  torch_compile: false  # Set to true if you want to try torch.compile
  torch_compile_backend: "inductor"
  torch_compile_mode: "default"

# Hardware optimizations
cuda_amp: true
dataloader_pin_memory: true
dataloader_num_workers: 0  # CRITICAL: Set to 0 to avoid multiprocessing issues
dataloader_prefetch_factor: 2  # Prefetch batches
dataloader_persistent_workers: false